# D1 I1 C1 -> GTZAN, LMS, 2D *
# D1 I2 C2 -> GTZAN, Waveform, SincNet *
# D1 I2 C3 -> GTZAN, Waveform, Conv1D *
# D1 I2 C4 -> GTZAN, Waveform, TCN
# D2 I1 C1 -> MTT, LMS, 2D *
output_file: {'origin': 'TUTO_task_Auto_Tagging.ipynb', 'ext': '_D1-I2-C3.ipynb'}
dataset:
    # D1
    {'base': gtzan-genre, 'problem': multiclass, 'annot_key': genre, 'n_out': 10}
    # D2
    #{'base': mtt, 'problem': multilabel, 'annot_key': tag, 'n_out': 50}
feature:
    # I1
    #{'type': lms, 'nb_band': 128, 'L_n': 2048, 'STEP_n': 1024, 'patch_L_frame': 64, 'patch_STEP_frame': 32}
    # I2
    {'type': waveform, 'patch_L_frame': 3200, 'patch_STEP_frame': 1000}
model:
    name: AutoTagging
    block_l:
    - sequential_l:
        - layer_l:
            # C1  Frequency/Time
            #- [LayerNorm, {'normalized_shape': -1}] #128,64 -> 128,256
            #- [Conv2d, {'in_channels': 1, 'out_channels': 80, 'kernel_size': [128, 5], 'stride': [1,1]}]
            #- [Squeeze, {'dim': [2]}] # --- (B, C, H=F, W=T) -> (B, C, T)
            # C2, C3, C4 Temporal
            - [LayerNorm, {'normalized_shape': [1, 3200]}]
            # C2 SincNet            
            #- [SincNet, {'in_channels': 1, 'out_channels': 80, 'kernel_size': 251, 'stride': 1, 'sr_hz': 22050}]
            #- [AbsLayer, empty]
            # C3 Conv1D
            - [Conv1d, {'in_channels': 1, 'out_channels': 80, 'kernel_size': 251, 'stride': 15}]
            # C4 TCN
            # - [Conv1dTCN, {'in_channels': 1, 'num_channels': [4, 8, 16, 32]}]
            # C2, C3, C4 All temporal
            - [MaxPool1d, {'kernel_size': 3, 'stride': 3}]
            - [LayerNorm, {'normalized_shape': -1}]
            - [Activation, LeakyReLU]
            - [Dropout, {'p': 0}]
        - layer_l:
            - [Conv1d, {'in_channels': -1, 'out_channels': 60, 'kernel_size': 5, 'stride': 1}]
            - [MaxPool1d, {'kernel_size': 3, 'stride': 3}] 
            - [LayerNorm, {'normalized_shape': -1}]
            - [Activation, LeakyReLU]
            - [Dropout, {'p': 0}]
        - layer_l:
            - [Conv1d, {'in_channels': -1, 'out_channels': 60, 'kernel_size': 5, 'stride': 1}]
            - [MaxPool1d, {'kernel_size': 3, 'stride': 3}]
            - [LayerNorm, {'normalized_shape': -1}]
            - [Activation, LeakyReLU]
            - [Dropout, {'p': 0}]
        - layer_l:
            - ['Permute', {'shape': [0, 2, 1]}] # --- (B, C, T) -> (B, T, C)
    - sequential_l:
        - layer_l:
            - [LayerNorm, {'normalized_shape': -1}]
            - [Linear, {'in_features': -1, 'out_features': 128}] # --- 2048 -> 128
            - [BatchNorm1dT, {'num_features': -1}]
            - [Activation, LeakyReLU]
            - [Dropout, {'p': 0}]
        - layer_l:
            - [Linear, {'in_features': -1, 'out_features': 128}] # --- 2048 -> 128
            - [BatchNorm1dT, {'num_features': -1}]
            - [Activation, LeakyReLU]
            - [Dropout, {'p': 0}]
        - layer_l:
            - [Linear, {'in_features': -1, 'out_features': 128}] # --- 2048 -> 128
            - [BatchNorm1dT, {'num_features': -1}]
            - [Activation, LeakyReLU]
            - [Dropout, {'p': 0}]
        #- layer_l:
            #- ['Permute', {'shape':[0, 2, 1]}] # --- (B, T, C) -> (B, C, T)
            #- [Mean, {'dim': 2}] # --- Suppose (B, C, T)
        - layer_l:
            - ['Permute', {'shape':[0, 2, 1]}] # --- (B, T, C) -> (B, C, T)
            - [UnSqueeze, {'dim': 2}]
        - layer_l:
            - [AutoPoolWeightSplit, empty]  # --- Suppose input (m, C, 1, W=T)
            - [Squeeze, {'dim': [2,3]}]
    - sequential_l:
        - layer_l:
            - [Linear, {'in_features': -1, 'out_features': 10}]
    #          - [Activation, Softmax]
